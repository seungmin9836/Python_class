{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "- 머신러닝의 한종류.\n",
    "- 여러 층(은닉층)을 가진 신경망을 사용해 머신러닝을 수행하는 것.\n",
    "- 이미지 인식, 음성 인식, 자연어 처리등의 다양한 분야에 활용.\n",
    "- 1980년대 부터 있었지만 현대에 와서 컴퓨터 성능이 좋아지고 비즈니스적으로 성공하면서 주목 받기 시작함.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning과 Machine Learning의 차이점\n",
    "- 가장 큰 차이점 Feature(특징량) 추출\n",
    "- Deep Learning은 스스로 학습을 하기 때문에 Machine Learning보다 많은 Data가 필요함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스마트폰을 구매할까?\n",
    "- 구매의 경우는 y 에 1\n",
    "- 그렇지 않은 경우는 y 에 0\n",
    "\n",
    "입력의 요인들 정리\n",
    "- X1 : 이번달 수입은 충분한가?\n",
    "- X2 : 최신 기능을 가지고 있는가?\n",
    "- X3 : 기존의 스마트폰에 문제가 있는가?\n",
    "\n",
    "X1, X2, X3의 가중치를 w1, w2, w3로 하였을 때 예상되는 조건들은 다음과 같습니다.\n",
    "- 부자인 경우에는 w1=1, w2=8, w3=2\n",
    "- 스마트폰에 문제가 생긴 사람의 가중치는 w1=2, w2=1, w3=8\n",
    "- 정기적으로 스마트폰을 구매하는 사람의 가중치는 w1=1, w2=8, w3=2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순전파(forward propagation)\n",
    "- 왼쪽에서 오른쪽으로 흘러가는 과정\n",
    "- 순전파에 의해 딥러닝의 출력값(y^)이 결정, 정답은(y()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실함수(Loss Function\n",
    "- 츨력값과 정다브이 차이\n",
    "- 출력값과 정답이 일치할수록 손실함수의 값은 작아진다.\n",
    "- 회귀에서는 평균제곱오차(Mean Sequared Error)\n",
    "\n",
    "\n",
    "- 분류에서는 크로스 엔트로피(Cross Entropy)를 사용\n",
    "- 매개변수(w,b)를 조절해서 손실함수의 값을 처저로 만드는 과정을 최적화(Optimization)dlfk gksek.\n",
    "- 최적화 과정은 Optimizer 를 통해 이뤄지며 Optimizer는 역전파(back propagation)과정을 수행해서 딥러닝 모델의 매개변수를 최적화한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  최적화(Optimization)\n",
    "- 대표적인 방법은 경사하강법\n",
    "- 반복적으로 손실함수에 대한 모델 매개변수의 기울기를 구한후 그 미분값의 반대방향으로 매개변수를 조절해 나가면 결국에는 최저 손실함수에 도달한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 역전파(back propagation)\n",
    "\n",
    "- Optimizer는 손실함수의 값을 최소화 하기 위해 역전파를 사용해 딥러닝 모델의 모든 매개변수를 변경한다.\n",
    "- 손실함수의 값을 최소화한다는 것은 정답과 예측값의 차이를 최소화 한다는 것이며 에러율을 최저로 줄인다는 의미."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝의 과대적합(overfitting)\n",
    "### 드롭 아웃(drop out)\n",
    "- 매개변수 중 일정량을 학습 중간마다 무작위로 사용하지 않는 방법\n",
    "- 드롭아웃을 사용하면 모델에 앙상블 효과를 준다.\n",
    "### 조기 종료(Early Stoppng)\n",
    "- 무조건 학습 반복 횟수를 높이면 학습시간이 길어져서 학습데이터만 성능이 좋은 현상이 발생(과적합)\n",
    "- 학습데이터로만 모델의 매개변수를 조정하고 검증데이터로 모델의 정확도를 측정한다.\n",
    "- 조기종료는 학습 횟수에 따라 검증 정확도가 꾸준히 떨어지는 시점이 발견되면 그 즉시 학습을 중단하고 최고점을 사용한다는 개념\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c34e8390e776d2ee205b71ed5a6130fee3cef8da5e87e926ce18e14f4a070d72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
